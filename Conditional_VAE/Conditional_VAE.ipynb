{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Variational Autoencoder(CVAE)\n",
    "Conditional Variational Autoencoder(CVAE)[1] is the extension of Variational Autoencoder(VAE)[2]\n",
    "\n",
    "The objective function in the Vanilla VAE is\n",
    "$$\n",
    "\\log P ( X ) - D _ { K L } [ Q ( z | X ) \\| P ( z | X ) ] = E [ \\log P ( X | z ) ] - D _ { K L } [ Q ( z | X ) \\| P ( z ) ]\n",
    "$$\n",
    "In Conditional- VAE, the encoder is Q(z|X, y), while the decoder is P(X|z, y)。The objective function above can be modified to be\n",
    "$$\n",
    "\\log P ( X | y ) - D _ { K L } [ Q ( z | X ,y ) \\| P ( z | X ,y ) ] = E [ \\log P ( X | z ,y ) ] - D _ { K L } [ Q ( z | X ,y ) \\| P ( z | y ) ]\n",
    "$$\n",
    "\n",
    "\n",
    "- - -\n",
    "[1]: Sohn, Kihyuk, Honglak Lee, and Xinchen Yan. “Learning Structured Output Representation using Deep Conditional Generative Models.” Advances in Neural Information Processing Systems. 2015.\n",
    "\n",
    "[2]: Kingma, Diederik P., and Max Welling. \"Auto-encoding variational bayes.\" arXiv preprint arXiv:1312.6114 (2013)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     29,
     34
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1,  ..., 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "no_cuda = False\n",
    "cuda_available = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "BATCH_SIZE =16\n",
    "EPOCH = 100\n",
    "SEED = 8\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda_available else {}\n",
    "train_loader = torch.utils.data.DataLoader( datasets.MNIST('./MNIST_data', train=True, download=True,                   transform=transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST('./MNIST_data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "print(test_loader.dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(794, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(30, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x, y):        \n",
    "        #y = y.type(torch.cuda.FloatTensor if cuda_available else torch.FloatTensor).unsqueeze(1)\n",
    "        \n",
    "        y = y.type(torch.cuda.FloatTensor if cuda_available else torch.FloatTensor)\n",
    "\n",
    "        h1 = F.relu(self.fc1(torch.cat((x, y), 1)))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        epsilon = torch.randn_like(std)\n",
    "        return mu + epsilon * std\n",
    "\n",
    "    def decode(self, z, y):\n",
    "        #y = y.type(torch.cuda.FloatTensor if cuda_available else torch.FloatTensor).unsqueeze(1)\n",
    "        y = y.type(torch.cuda.FloatTensor if cuda_available else torch.FloatTensor)\n",
    "\n",
    "        h3 = F.relu(self.fc3(torch.cat((z, y), 1)))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        mu, logvar = self.encode(x.view(-1, 784), y)\n",
    "        \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z, y), mu, logvar\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction = 'sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "model = CVAE().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2onehot(idx, n):\n",
    "    assert torch.max(idx).item() < n and idx.dim()<=2\n",
    "    idx2dim = idx.view(-1,1) # change from 1-dim tensor to 2-dim tensor\n",
    "    onehot = torch.zeros(idx2dim.size(0),n).scatter_(1,idx2dim,1)\n",
    "\n",
    "    return onehot\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "     \n",
    "        data = data.round().to(device) #[64, 1, 28, 28]\n",
    "        label = idx2onehot(label,10).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data, label)\n",
    "        \n",
    "        loss = loss_function(recon_batch, data.view(-1, data.shape[2]*data.shape[3]), mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 77.7605\n",
      "====> Test set loss: 80.3823\n",
      "====> Epoch: 2 Average loss: 77.7095\n",
      "====> Test set loss: 80.2210\n",
      "====> Epoch: 3 Average loss: 77.6666\n",
      "====> Test set loss: 80.2843\n",
      "====> Epoch: 4 Average loss: 77.6426\n",
      "====> Test set loss: 80.4796\n",
      "====> Epoch: 5 Average loss: 77.6790\n",
      "====> Test set loss: 79.8406\n"
     ]
    }
   ],
   "source": [
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, (data, label) in enumerate(test_loader):\n",
    "            data = data.round().to(device)\n",
    "            label = idx2onehot(label,10).to(device)\n",
    "\n",
    "            recon_batch, mu, logvar = model(data, label)                                    \n",
    "            test_loss += loss_function(recon_batch, data.view(-1, data.shape[2]*data.shape[3]), mu, logvar).item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCH + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # sampling\n",
    "        sample = torch.randn(16, 20).to(device)\n",
    "      \n",
    "        c = torch.zeros(sample.shape[0],1).fill_(5).type(torch.LongTensor)\n",
    "      \n",
    "        c = idx2onehot(c,10).to(device)\n",
    "\n",
    "        sample = model.decode(sample, c).cpu()\n",
    "\n",
    "        generated_image = sample.round()\n",
    "        image_save_path = 'images'\n",
    "        save_image(generated_image.view(16, 1, 28, 28),os.path.join(image_save_path,'sample_{}.png'.format(str(epoch))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 121.26086950302124,
   "position": {
    "height": "40px",
    "left": "691.4674072265625px",
    "right": "22.0108699798584px",
    "top": "121.98369598388672px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
